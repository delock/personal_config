#!/home/akey/anaconda3/envs/ai/bin/python
#!/home/gma/miniforge3/bin/python
import os
import sys
import json
import signal
import time
from openai import OpenAI
from googlesearch import search
from rich.console import Console
from rich.markdown import Markdown as richMarkdown
#from rich.live import Live
import requests
from bs4 import BeautifulSoup
from textual.app import App, ComposeResult
from textual.binding import Binding
from textual.reactive import var
from textual.widgets import Footer, Markdown
from textual.worker import Worker, get_current_worker
from textual import work

# Initialize Rich console
console = Console()

# Environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_URL = os.getenv("OPENAI_API_URL")
OPENAI_API_MODEL = os.getenv("OPENAI_API_MODEL")
OPENAI_API_REASONER = os.getenv("OPENAI_API_REASONER")

# Check if environment variables are set
if not OPENAI_API_KEY or not OPENAI_API_URL or not OPENAI_API_MODEL:
    console.print("[bold red]Error:[/bold red] Environment variables OPENAI_API_KEY, OPENAI_API_URL, and OPENAI_API_MODEL must be set.")
    sys.exit(1)

# Initialize OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_URL)

def query_deepseek(messages, stream=False, need_reasoning=False):
    try:
        response = client.chat.completions.create(
            model=OPENAI_API_MODEL if not need_reasoning else OPENAI_API_REASONER,
            messages=messages,
            stream=stream
        )
        if stream:
            return response
        else:
            return response.choices[0].message.content
    except Exception as e:
        console.print(f"[bold red]Error:[/bold red] {e}")
        sys.exit(1)

def decide_web_search(question):
    messages = [
        {"role": "system", "content": "You are a helpful assistant that decides if a web search is needed. Output in JSON format."},
        {"role": "user", "content": f"Question: {question}\n\nOutput JSON format: {{\"need_search\": true/false, \"keywords\": \"search keywords\"}}"}
    ]
    response = query_deepseek(messages)
    response = response.replace("```json", "").replace("```", "")
    try:
        decision = json.loads(response)
        return decision.get("need_suarch", False), decision.get("keywords", "")
    except json.JSONDecodeError:
        return False, ""

def pick_search_link(question, search_results):
    references = "\n".join([f"- [{result['title']}]({result['url']}): {result['description']}" for result in search_results])
    messages = [
        {"role": "system", "content": "You are a helpful assistant that decides which search result is most relevant to your question.  Output in JSON format."},
        {"role": "user", "content": f"Question: {question}\nSearch results {references}\n\nOutput JSON format: {{\"url\": url}}"}
    ]
    response = query_deepseek(messages)
    response = response.replace("```json", "").replace("```", "")
    try:
        decision = json.loads(response)
        return decision.get("url", "")
    except json.JSONDecodeError:
        return False, ""

# give web page scrape text, and key words, extract relevant part from text
# according to keywords, using deepseek api
def extract_relevant_text(text, keywords):
    messages = [
        {"role": "system", "content": "You are a helpful assistant that extracts relevant text from a web page. Keep text less than 1000 words. Output in JSON format."},
        {"role": "user", "content": f"Text: {text}\nKeywords: {keywords}\n\nOutput JSON format: {{\"relevant_text\": \"extracted text\"}}"}
    ]
    response = query_deepseek(messages)
    response = response.replace("```json", "").replace("```", "")
    try:
        extraction = json.loads(response)
        return extraction.get("relevant_text", "")
    except json.JSONDecodeError:
        return ""

def strip_empty_lines(text):
    # Split the text into lines, filter out empty lines, and join them back
    return '\n'.join([line for line in text.splitlines() if line.strip()])

def perform_web_search(keywords, question):
    search_results = []
    for result in search(keywords, advanced=True, num_results=20):
        text = result.description
        search_results.append({
            "title": result.title,
            "url": result.url,
            "description": text
        })
    url = pick_search_link(question, search_results)
    try:
        print ("Extracting the most relvant url")
        response = requests.get(url)
        html_content = response.text
        soup = BeautifulSoup(html_content, "html.parser")
        text = strip_empty_lines(soup.get_text())
        #print ("Extracting the most relvant contents")
        #text = extract_relevant_text(text, keywords)
        #print (text)
    except Exception as e:
        text = ""
        pass
    return search_results, text

class MarkdownApp(App):
    """A simple Markdown viewer application."""

    BINDINGS = [
        Binding("q", "exit", "Exit", tooltip="Exit this app"),
    ]

    markdown_content = ""
    def __init__(self) -> None:
        self.output = Markdown()
        self.info = Markdown()
        self._debug = Markdown()
        """Initialize the MarkdownApp."""
        super().__init__()

    def beautify_and_stream_output(self, response):
        cot_content = ""
        t0 = time.time()
        interval = 0.0
        last_mark = 0
        mark_step = 16
        for chunk in response:
            if chunk.choices:
                content = chunk.choices[0].delta.content
                # check if reasoning_content attr exists
                if hasattr(chunk.choices[0].delta, 'reasoning_content'):
                    reasoning_content = chunk.choices[0].delta.reasoning_content
                    if reasoning_content != None:
                        cot_content += reasoning_content
                else:
                  if content != None:
                      self.markdown_content += f'{content}'
                if time.time() - t0 > interval:
                    # quote every line in cot_content
                    quote_cot_content = "" if cot_content=="" else "\n".join([f"> {line}" for line in cot_content.split("\n")])
                    self.call_from_thread(self.output.update, (f'{quote_cot_content}\n{self.markdown_content}'))
                    t0 = time.time()
        self.call_from_thread(self.output.update, (f'{self.markdown_content}'))

    @work(thread=True)
    def do_work(self):
        if len(sys.argv) < 2:
            self.call_from_thread(self.info.update, ("Error: No question provided."))
            return
        if sys.argv[1] == '-r':
            need_reasoning = True;
            question = " ".join(sys.argv[2:])
        else:
            need_reasoning = False;
            question = " ".join(sys.argv[1:])
        if not question:
            self.call_from_thread(self.info.update, ("Error: No question provided."))

        self.call_from_thread(self.info.update, (f"**Analyzing question...**\n*{question}*"))
        need_search, keywords = decide_web_search(question)

        if need_search:
            self.call_from_thread(self.info.update, (f"**Web search needed for keywords:** *{keywords}*"))
            search_results, text = perform_web_search(keywords, question)
            references = "\n".join([f"- [{result['title']}]({result['url']}): {result['description']}" for result in search_results])
            self.call_from_thred(self._debug.update, (f"Search results: \n{references}\n---\nExtracted text: \n{text}"))
            messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": f"{question}\n\nReferences:\n{references}\n\nExtracted text:\n{text}"}
            ]
        else:
            self.call_from_thread(self.info.update, (f"**No web search needed.**"))
            messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": question}
            ]

        # print references and text into a file named run.log
        with open("run.log", "a") as f:
            f.write(f"Question: {question}\n")
            if need_search:
                f.write(f"References:\n{references}\n")
                f.write(f"Extracted text:\n{text}\n")
        self.call_from_thread(self.info.update, ("**Generating answer...**"))
        response = query_deepseek(messages, stream=True, need_reasoning=need_reasoning)
        self.beautify_and_stream_output(response)
        self.call_from_thread(self.info.update, ("*Done*"))


    def compose(self) -> ComposeResult:
        #yield Footer()
        yield self.output
        yield self.info
        yield self._debug

    async def on_mount(self) -> None:
        self.do_work()

    #def on_markdown_viewer_navigator_updated(self) -> None:
        #"""Refresh bindings for forward / back when the document changes."""
        #self.refresh_bindings()

    #def action_toggle_table_of_contents(self) -> None:
        #"""Toggles display of the table of contents."""
        #self.markdown.show_table_of_contents = (
            #not self.markdown.show_table_of_contents
        #)

    async def action_exit(self) -> None:
        """Exit the application."""
        #if self.markdown_content != "":
            #console.print(richMarkdown(self.markdown_content))
        self.exit()

    def check_action(self, action: str, _) -> bool | None:
        """Check if certain actions can be performed."""
        #if action == "forward" and self.markdown.navigator.end:
            ## Disable footer link if we can't go forward
            #return None
        #if action == "back" and self.markdown.navigator.start:
            ## Disable footer link if we can't go backward
            #return None
        # All other keys display as normal
        return True

if __name__ == "__main__":
    markdown = MarkdownApp()
    markdown.run()
